{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dd56e0-f574-49a7-9778-f8c03741ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizerFast, AlbertForQuestionAnswering\n",
    "import random\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116c11b9-4e7f-4fdc-b997-1959e3b0e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"UWB-AIR/Czert-B-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c44d98-b7ff-4df2-9df7-647c2053acb1",
   "metadata": {},
   "source": [
    "### Load sqad from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6934b5a1-d1b5-4df8-8e6e-c8f41b5dcd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"sqad.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "#json_data[0]\n",
    "random.shuffle(json_data)\n",
    "#json_data = json_data.sample(frac=1).reset_index(drop=True)\n",
    "train = json_data[:9954] #80%\n",
    "test = json_data[9954:] #20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57391ec-cdd4-4736-8a25-eadd02d160c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12443\n",
      "9954 80 %\n",
      "2489 20 %\n"
     ]
    }
   ],
   "source": [
    "print(len(json_data))\n",
    "print(len(train), int(round(len(train)/len(json_data)*100)),\"%\")\n",
    "print(len(test), int(round(len(test)/len(json_data)*100)),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d64585-9eed-44ef-83a5-a8421203cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jak se nazývá východní část Moldávie? ['Besarábie']\n",
      "Který někdejší rytířský a panský český rod odvozoval svůj přídomek od města Vlašim? ['Jankovští z Vlašimi']\n",
      "Kdy vznikla Fakulta informatiky na Masarykově univerzitě? ['1994']\n",
      "Kdy byl natočen film Skřivánci na niti? ['1969']\n",
      "V kterém československém filmu byl poprvé použit zvuk? ['Když struny lkají']\n",
      "Kterým filmem debutoval režisér Ivan Passer? ['Intimní osvětlení']\n",
      "Jaká je zkratka Evropské kosmické agentury? ['ESA']\n",
      "Surikaty bydlí i v zoo? ['Surikata je velmi častým chovancem zoo.']\n",
      "Jaké je druhé nejčetnější české křestní jméno? ['Jan']\n",
      "Jak se nazývá hrdelní vak ptáků pro uskladnění potravy? ['vole']\n"
     ]
    }
   ],
   "source": [
    "for i in json_data[:10]:\n",
    "    print(i[\"question\"],i[\"answers\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdf8cc5-d680-4471-a5a1-a22710ccf2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b2d916-7754-4da5-a3b8-121ded2fe8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [1451], 'text': ['Besarábie']}</td>\n",
       "      <td>Moldávie (rumunsky Moldova, starším českým ozn...</td>\n",
       "      <td>11355</td>\n",
       "      <td>Jak se nazývá východní část Moldávie?</td>\n",
       "      <td>Jak se nazývá východní část Moldávie?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [0], 'text': ['Jankovští z Vl...</td>\n",
       "      <td>Jankovští z Vlašimi jsou někdejší rytířský a p...</td>\n",
       "      <td>9786</td>\n",
       "      <td>Který někdejší rytířský a panský český rod odv...</td>\n",
       "      <td>Který někdejší rytířský a panský český rod odv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [290], 'text': ['1994']}</td>\n",
       "      <td>Fakulta informatiky Masarykovy univerzity (FI ...</td>\n",
       "      <td>10186</td>\n",
       "      <td>Kdy vznikla Fakulta informatiky na Masarykově ...</td>\n",
       "      <td>Kdy vznikla Fakulta informatiky na Masarykově ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [78], 'text': ['1969']}</td>\n",
       "      <td>Skřivánci na niti je český hořce poetický film...</td>\n",
       "      <td>4277</td>\n",
       "      <td>Kdy byl natočen film Skřivánci na niti?</td>\n",
       "      <td>Kdy byl natočen film Skřivánci na niti?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [1295], 'text': ['Když struny...</td>\n",
       "      <td>Česká kinematografie je souhrnné označení pro ...</td>\n",
       "      <td>4152</td>\n",
       "      <td>V kterém československém filmu byl poprvé použ...</td>\n",
       "      <td>V kterém československém filmu byl poprvé použ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0    {'answer_start': [1451], 'text': ['Besarábie']}   \n",
       "1  {'answer_start': [0], 'text': ['Jankovští z Vl...   \n",
       "2          {'answer_start': [290], 'text': ['1994']}   \n",
       "3           {'answer_start': [78], 'text': ['1969']}   \n",
       "4  {'answer_start': [1295], 'text': ['Když struny...   \n",
       "\n",
       "                                             context     id  \\\n",
       "0  Moldávie (rumunsky Moldova, starším českým ozn...  11355   \n",
       "1  Jankovští z Vlašimi jsou někdejší rytířský a p...   9786   \n",
       "2  Fakulta informatiky Masarykovy univerzity (FI ...  10186   \n",
       "3  Skřivánci na niti je český hořce poetický film...   4277   \n",
       "4  Česká kinematografie je souhrnné označení pro ...   4152   \n",
       "\n",
       "                                            question  \\\n",
       "0              Jak se nazývá východní část Moldávie?   \n",
       "1  Který někdejší rytířský a panský český rod odv...   \n",
       "2  Kdy vznikla Fakulta informatiky na Masarykově ...   \n",
       "3            Kdy byl natočen film Skřivánci na niti?   \n",
       "4  V kterém československém filmu byl poprvé použ...   \n",
       "\n",
       "                                               title  \n",
       "0              Jak se nazývá východní část Moldávie?  \n",
       "1  Který někdejší rytířský a panský český rod odv...  \n",
       "2  Kdy vznikla Fakulta informatiky na Masarykově ...  \n",
       "3            Kdy byl natočen film Skřivánci na niti?  \n",
       "4  V kterém československém filmu byl poprvé použ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b42153-f999-4778-b9aa-569616afbf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [12], 'text': ['levostranný']}</td>\n",
       "      <td>Dřevnice je levostranný přítok řeky Moravy ve ...</td>\n",
       "      <td>12242</td>\n",
       "      <td>Jaký přítok je Dřevnice?</td>\n",
       "      <td>Jaký přítok je Dřevnice?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [0], 'text': ['Samuel Barclay...</td>\n",
       "      <td>Samuel Barclay Beckett [Bekit] (13. dubna 1906...</td>\n",
       "      <td>2490</td>\n",
       "      <td>Kde se narodil Samuel Beckett?</td>\n",
       "      <td>Kde se narodil Samuel Beckett?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [216], 'text': ['Josef Ressel']}</td>\n",
       "      <td>Buzola (také busola) je jednoduchý přístroj pr...</td>\n",
       "      <td>5571</td>\n",
       "      <td>Který český vynálezce sestrojil první buzolu?</td>\n",
       "      <td>Který český vynálezce sestrojil první buzolu?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [2084], 'text': ['1869']}</td>\n",
       "      <td>Deoxyribonukleová kyselina, běžně označovaná D...</td>\n",
       "      <td>7325</td>\n",
       "      <td>Ve kterém roce byla popsána deoxyribonukleová ...</td>\n",
       "      <td>Ve kterém roce byla popsána deoxyribonukleová ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [168], 'text': ['strojové ins...</td>\n",
       "      <td>Centrální procesorová jednotka (zkratka CPU, a...</td>\n",
       "      <td>3770</td>\n",
       "      <td>Co vykonává procesor?</td>\n",
       "      <td>Co vykonává procesor?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0    {'answer_start': [12], 'text': ['levostranný']}   \n",
       "1  {'answer_start': [0], 'text': ['Samuel Barclay...   \n",
       "2  {'answer_start': [216], 'text': ['Josef Ressel']}   \n",
       "3         {'answer_start': [2084], 'text': ['1869']}   \n",
       "4  {'answer_start': [168], 'text': ['strojové ins...   \n",
       "\n",
       "                                             context     id  \\\n",
       "0  Dřevnice je levostranný přítok řeky Moravy ve ...  12242   \n",
       "1  Samuel Barclay Beckett [Bekit] (13. dubna 1906...   2490   \n",
       "2  Buzola (také busola) je jednoduchý přístroj pr...   5571   \n",
       "3  Deoxyribonukleová kyselina, běžně označovaná D...   7325   \n",
       "4  Centrální procesorová jednotka (zkratka CPU, a...   3770   \n",
       "\n",
       "                                            question  \\\n",
       "0                           Jaký přítok je Dřevnice?   \n",
       "1                     Kde se narodil Samuel Beckett?   \n",
       "2      Který český vynálezce sestrojil první buzolu?   \n",
       "3  Ve kterém roce byla popsána deoxyribonukleová ...   \n",
       "4                              Co vykonává procesor?   \n",
       "\n",
       "                                               title  \n",
       "0                           Jaký přítok je Dřevnice?  \n",
       "1                     Kde se narodil Samuel Beckett?  \n",
       "2      Který český vynálezce sestrojil první buzolu?  \n",
       "3  Ve kterém roce byla popsána deoxyribonukleová ...  \n",
       "4                              Co vykonává procesor?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6675443b-df9a-4ff6-a305-44ebb2fe3670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 161/161 [00:00<00:00, 156kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 675/675 [00:00<00:00, 676kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 209k/209k [00:00<00:00, 422kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 112kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='UWB-AIR/Czert-B-base-cased', vocab_size=30000, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "827fa09e-8d04-4f10-afaf-d69887dc0588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 5935, 9402, 2183, 12393, 3, 26054, 2116, 9457, 4166, 90, 18315, 1011, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[CLS] Česko Slovensko má talent [SEP] Masarykova Univerzita v Brne [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"Česko Slovensko má talent\", \"Masarykova Univerzita v Brne\"))\n",
    "print(tokenizer.decode([2, 5935, 9402, 2183, 12393, 3, 26054, 2116, 9457, 4166, 90, 18315, 1011, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f01b62-119c-4604-8ae8-b750cf6647b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of tokenized question and context:  1667\n",
      "Maximum input length for current model:  384\n",
      "Length of tokenized question and context with turnication:  384\n",
      "Length of tokenized question and context with document stride: [384, 384, 384, 384, 384, 384, 209]\n"
     ]
    }
   ],
   "source": [
    "# Max input sequence length is 512 so we set the max length to 384 and the maximum ovelap on sliding window to 128\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "\n",
    "random_example = df_train.iloc[4]\n",
    "tokenized_example = tokenizer(\n",
    "    random_example[\"question\"],\n",
    "    random_example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(\"Length of tokenized question and context: \",len(tokenizer(random_example[\"question\"],random_example[\"context\"])[\"input_ids\"]))\n",
    "print(\"Maximum input length for current model: \", max_length)\n",
    "print(\"Length of tokenized question and context with turnication: \",\n",
    "      len(tokenizer(\n",
    "          random_example[\"question\"],\n",
    "          random_example[\"context\"],\n",
    "          max_length = max_length,\n",
    "          truncation = \"only_second\")\n",
    "          [\"input_ids\"]))\n",
    "print(\"Length of tokenized question and context with document stride: \",end=\"\")\n",
    "print([len(x) for x in tokenized_example[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9d6b5d7-2553-4a36-b80b-03a535903a02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP] časové pásmo je ta část země, která používá stejný standardní čas. původně používali lidé sluneční čas, který má ovšem tu nevýhodu, že se liší od místa k místu. s rozvojem dopravy a komunikace byla tato nevýhoda stále výraznější, takže se postupem času přešlo na pásmový čas, kdy celá oblast země, zhruba 15 ° kolem daného poledníku, používá stejný čas, který je určen svým posunem od utc, koordinovaného světového času ( většinou je posun určen celistvým počtem hodin, jsou však i výjimky ). základním časovým pásmem je pásmo, ve kterém platí utc a které se rozkládá kolem nultého poledníku, který prochází královskou observatoří v greenwichi ( londýn, anglie ). z toho důvodu se pásmovému času odpovídajícímu utc někdy říká greenwichský čas ( gmt, greenwich mean time ). ostatní časová pásma jsou popsána rozdílem počtu hodin, o které se v nich platný čas liší od utc. např. středoevropský čas ( seč ) je označen jako utc + 1, neboť je vzhledem k utc posunut o hodinu napřed ( tzn. ve chvíli, kdy je 12. 00 utc, je ve střední evropě 13. 00 ). na západní polokouli je čas oproti utc posunut zpět ( např. v new yorku, usa platí časové pásmo utc - 5 ), na východní polokouli platí čas, který je před utc ( např. v tokiu, japonsko je časové pásmo utc + 9 ). ideální časová pásma by se navzájem lišila o celý počet hodin, takže by zemi rozdělila na přesné pruhy široké 15 °. to by však znamenalo, že státy, které procházejí hranicí takových teoretických pásem, by musely používat dvě časová pásma, jakkoli by byla jejich rozlo [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP], je ve střední evropě 13. 00 ). na západní polokouli je čas oproti utc posunut zpět ( např. v new yorku, usa platí časové pásmo utc - 5 ), na východní polokouli platí čas, který je před utc ( např. v tokiu, japonsko je časové pásmo utc + 9 ). ideální časová pásma by se navzájem lišila o celý počet hodin, takže by zemi rozdělila na přesné pruhy široké 15 °. to by však znamenalo, že státy, které procházejí hranicí takových teoretických pásem, by musely používat dvě časová pásma, jakkoli by byla jejich rozloha malá. z praktických důvodů se proto stanovily takové tvary časových pásem, které se přizpůsobují hranicím států či jiných územních celků. některá časová pásma pak používají čas, který se od utc neliší o celý počet hodin, ale o půlhodiny, či dokonce čtvrthodiny. čas aktuálně platný na daném místě není dán pouze časovým pásmem, do kterého místo patří, ale také tím, jestli je v daném místě používán letní čas. skutečná odchylka místně platného času od utc se tedy může v průběhu roku měnit. pokud se po přičtení časového rozdílu k utc překročí půlnoc, změní se i datum platné na daném místě ( např. pokud je pátek, 18. 00 utc, pak v pásmu utc + 8 je sobota, 02. 00 ). datum se mění též při překročení tzv. datové čáry, která prochází zhruba po 180. poledníku a která tvoří hranici mezi pásmy utc + 12 a utc - 12. při překročení této čáry směrem na západ ( což ovšem znamená ze západní polokoule na východní ) se přechází z pásma utc - 12 do pásma utc + 12, takže plat [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP]. pokud se po přičtení časového rozdílu k utc překročí půlnoc, změní se i datum platné na daném místě ( např. pokud je pátek, 18. 00 utc, pak v pásmu utc + 8 je sobota, 02. 00 ). datum se mění též při překročení tzv. datové čáry, která prochází zhruba po 180. poledníku a která tvoří hranici mezi pásmy utc + 12 a utc - 12. při překročení této čáry směrem na západ ( což ovšem znamená ze západní polokoule na východní ) se přechází z pásma utc - 12 do pásma utc + 12, takže platný čas se zvýší o 24 hodin, tzn. čas se nemění, ale datum se posune o jeden den vpřed. při přechodu směrem na východ opačně. v následujícím seznamu je u každého časového pásma uvedena odchylka od utc, jednopísmenné označení používané námořníky ( které lze pomocí hláskovací tabulky převést na jednoslovný název ) a případná dále používaná označení časového pásma. u každého pásma je pak uveden seznam států či území, která pásmo používají. v seznamu jsou hvězdičkou ( * ) označena území, ve kterých se používá letní čas. bakerův ostrov ( neobydlený ) howlandův ostrov ( neobydlený ) americká samoa atol midway ( usa ) niue cookovy ostrovy části francouzské polynésie johnstonův atol části spojených států ( havaj, aleutské ostrovy ) * část francouzské polynésie (. markézy ) části francouzské polynésie část spojených států ( aljaška ) * části kanady ( yukon, britská kolumbie ) * části mexika ( baja california ) * pitcairnovy ostrovy části spojených států ( kalifornie,. nevada, oregon, washington ) * [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP] používá letní čas. bakerův ostrov ( neobydlený ) howlandův ostrov ( neobydlený ) americká samoa atol midway ( usa ) niue cookovy ostrovy části francouzské polynésie johnstonův atol části spojených států ( havaj, aleutské ostrovy ) * část francouzské polynésie (. markézy ) části francouzské polynésie část spojených států ( aljaška ) * části kanady ( yukon, britská kolumbie ) * části mexika ( baja california ) * pitcairnovy ostrovy části spojených států ( kalifornie,. nevada, oregon, washington ) * části kanady ( alberta ) * části mexika ( chihuahua, sonora, baja california sur, sinaloa, nayarit ) * části spojených států ( arizona., colorado ) * belize část ekvádor ( galapágy ) salvador guatemala honduras části kanady ( manitoba, saskatchewan ) * kostarika většina mexika * nikaragua části spojených států ( illinois, texas ) * bahamy. * ekvádor haiti část chile ( velikonoční ostrov ) * jamajka části kanady ( ontario, québec ) * kajmanské ostrovy kolumbie kuba * panama peru turks a caicos * část mexika ( quintana roo ) části spojených států. ( východní pobřeží washington, d. c., new york ) * anguilla americké i britské panenské ostrovy antigua a barbuda aruba barbados bermudy * bolívie části brazílie ( amazonas ) * curaçao dominika dominikánská republika falklandy * grenada část grónska. * guadeloupe guyana části kanady [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP]ční ostrov ) * jamajka části kanady ( ontario, québec ) * kajmanské ostrovy kolumbie kuba * panama peru turks a caicos * část mexika ( quintana roo ) části spojených států. ( východní pobřeží washington, d. c., new york ) * anguilla americké i britské panenské ostrovy antigua a barbuda aruba barbados bermudy * bolívie části brazílie ( amazonas ) * curaçao dominika dominikánská republika falklandy * grenada část grónska. * guadeloupe guyana části kanady ( nové skotsko ) * martinik montserrat paraguay * portoriko sint maarten svatá lucie svatý kryštof a nevis svatý vincenc a grenadiny trinidad a tobago venezuela části kanady ( newfoundland ) * argentina části brazílie brasila., rio de janeiro, sã paulo * francouzská guyana většina grónska * chile ( kontinentální ) * saint - pierre a miquelon * surinam uruguay část brazílie ( fernando de noronha ) jižní georgie a jižní sandwichovy ostrovy část grónska *. kapverdy část portugalska ( azorské ostrovy ) * burkina faso faerské ostrovy * gambie ghana část grónska guinea guinea - bissau irsko * island libérie mali maroko mauritánie pobřeží slonoviny portugalsko ( kontinentální, madeira ) * senegal sierra leone svatá helena,. ascension a tristan da cunha svatý tomáš a princův ostrov část španělska ( kanárské ostrovy ) * togo velká británie * albánie * alžírsko andorra * ang [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP]wichovy ostrovy část grónska *. kapverdy část portugalska ( azorské ostrovy ) * burkina faso faerské ostrovy * gambie ghana část grónska guinea guinea - bissau irsko * island libérie mali maroko mauritánie pobřeží slonoviny portugalsko ( kontinentální, madeira ) * senegal sierra leone svatá helena,. ascension a tristan da cunha svatý tomáš a princův ostrov část španělska ( kanárské ostrovy ) * togo velká británie * albánie * alžírsko andorra * angola belgie * benin bosna a hercegovina * čad černá hora * česko * dánsko. * francie * gabon gibraltar * chorvatsko * itálie * libye lichtenštejnsko * lucembursko * kamerun kongo maďarsko * makedonie * malta * monako * namibie * německo * niger nigérie nizozemsko * norsko *. polsko * rakousko * rovníková guinea san marino * slovensko * slovinsko * srbsko * středoafrická republika svalbard * španělsko * švédsko * švýcarsko * tunisko vatikán * botswana bulharsko * burundi demokratická republika kongo egypt estonsko. * finsko * pásmo gazy * izrael * jihoafrická republika jordánsko * kypr * lotyšsko * lesotho libanon * litva * malawi moldavsko * mosambik rumunsko * rwanda řecko * svazijsko sýrie * turecko * ukrajina. * západní břeh jordánu * zambie zimbabwe bahrajn bělorusko * džibutsko eritrea etiopie irák * jemen katar keňa komory kuvajt madagaskar mayotte část ruska ( kaliningradská oblast ) * saúdská arábie somálsko súdán tan [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP] * burundi demokratická republika kongo egypt estonsko. * finsko * pásmo gazy * izrael * jihoafrická republika jordánsko * kypr * lotyšsko * lesotho libanon * litva * malawi moldavsko * mosambik rumunsko * rwanda řecko * svazijsko sýrie * turecko * ukrajina. * západní břeh jordánu * zambie zimbabwe bahrajn bělorusko * džibutsko eritrea etiopie irák * jemen katar keňa komory kuvajt madagaskar mayotte část ruska ( kaliningradská oblast ) * saúdská arábie somálsko súdán tanzanie uganda írán * arménie * ázerbájdžán *. gruzie * mauricius omán réunion evropská část ruska a republika krym ( sporné území ) * seychely spojené arabské emiráty afghánistán části kazachstánu * maledivy pákistán části ruska * tádžikistán turkmenistán uzbekistán indie šrí lanka nepál bangladéš bhútán kyrgyzstán * části kazachstánu. * části ruska ( čeljabinská oblast, sverdlovská oblast ) * kokosové ostrovy myanmar část indonésie ( sumatra, jáva, část kalimantanu ) kambodža laos část ruska ( novosibirská oblast ) * thajsko vietnam vánoční ostrov část austrálie. ( západní austrálie ) brunej čína ( celá ) hongkong část indonésie ( sulawesi ) macao malajsie mongolsko ( většina ) * filipíny části ruska ( krasnojarský kraj ) * singapur čínská republika severní korea část austrálie východní. timor část indonésie ( západní papua ) japonsko jižní korea palau části ruska ( irkutská oblast ) * část austrálie ( jižní austrálie, [SEP]\n",
      "[CLS] kolem kterého poledníku se rozkládá základní časové pásmo? [SEP] myanmar část indonésie ( sumatra, jáva, část kalimantanu ) kambodža laos část ruska ( novosibirská oblast ) * thajsko vietnam vánoční ostrov část austrálie. ( západní austrálie ) brunej čína ( celá ) hongkong část indonésie ( sulawesi ) macao malajsie mongolsko ( většina ) * filipíny části ruska ( krasnojarský kraj ) * singapur čínská republika severní korea část austrálie východní. timor část indonésie ( západní papua ) japonsko jižní korea palau části ruska ( irkutská oblast ) * část austrálie ( jižní austrálie, severní teritorium ) část austrálie ( queensland, nový jižní wales, tasmánie,. victoria ) guam části mikronésie papua - nová guinea ( většina ) části ruska ( zabajkalský kraj ) * severní mariany nová kaledonie část austrálie ( ostrov lorda howa ) části mikronésie nová kaledonie papua - nová guinea ( autonomní území bougainville ) části. ruska ( přímořský kraj ) * šalamounovy ostrovy vanuatu norfolk fidži část kiribati marshallovy ostrovy nauru nový zéland části ruska ( kamčatský kraj ) * tuvalu wakeův ostrov wallis a futuna část nového zélandu ( chathamské ostrovy ) část kiribati samoa tokelau ( nový zéland ) tonga část kiribati [SEP]\n"
     ]
    }
   ],
   "source": [
    "#see the overlap with the stride\n",
    "for i in tokenized_example[\"input_ids\"]:\n",
    "    print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b097abc-fdfe-416b-a0ab-b797d29a17b3",
   "metadata": {},
   "source": [
    "To be able to create dataset for training we have to find starting and ending positions in every tokenized pair (question, context).\n",
    "Since the dataset already dontains the starting positions of the answer in text we only need to add ending positions.\n",
    "We can use `return_offsets_mapping` to be able to see span of every token from input IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe676c72-5839-45fd-8d51-32fdfbe9261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 4), (5, 7), (8, 12), (12, 15), (16, 24), (25, 30), (30, 33), (34, 42), (42, 43), (0, 0), (0, 8), (9, 14), (14, 17), (18, 26), (27, 28), (28, 36), (37, 42), (43, 49), (49, 50)]\n",
      "##cké\n",
      "cké\n"
     ]
    }
   ],
   "source": [
    "random_example = df_train.iloc[6]\n",
    "tokenized_example_offset = tokenizer(\n",
    "    random_example[\"question\"],\n",
    "    random_example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    stride=doc_stride,\n",
    "    return_overflowing_tokens = True,\n",
    "    return_offsets_mapping = True\n",
    ")\n",
    "print(tokenized_example_offset[\"offset_mapping\"][0][:20])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer(random_example[\"question\"])[\"input_ids\"][7]))\n",
    "print(random_example[\"question\"][tokenized_example_offset[\"offset_mapping\"][0][7][0]:tokenized_example_offset[\"offset_mapping\"][0][7][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a3bda54-d72f-4717-9cf8-68d6c866f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898 pro čavčuvenský\n",
      "Korjačtina je jazyk z malé izolované čukotsko-kamčatské rodiny, kterým hovoří Korjaci, malý národ sídlící na ruském Dálném východě, především na Kamčatském poloostrově. Při sčítání lidu v roce 2002 uvedlo znalost korjackého jazyka 3 019 osob, tedy 34,5 % z celkového počtu Korjaků v Rusku. Procento Korjaků, kteří jazyk bez potíží ovládají, je však patrně mnohem nižší, podle některých odhadů jen 5,4 %. Z hlediska morfologické typologie se korjačtina řadí k aglutinačním jazykům s výskytem sufixů, p\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(random_example[\"answers\"][\"answer_start\"][0],random_example[\"answers\"][\"text\"][0])\n",
    "print(random_example[\"context\"][:500])\n",
    "print(tokenized_example_offset.sequence_ids().index(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a4fd615-fc27-4619-b2e9-e34be8ed6c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] pro který dialekt byla vytvořena první korjacká abeceda?\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_example_offset.input_ids[0][:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d31a66-4753-494c-8063-c8d06a8a8fcb",
   "metadata": {},
   "source": [
    "#### Function tokenizes row, splits into multiple parts if lenght > max_length and sets starting and ending positions of answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dbe5e4f-d4ea-45aa-8d59-319a3b31614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_start_token_index(ex):\n",
    "    return [x.index(1) for x in ex.token_type_ids]\n",
    "\n",
    "def context_end_token_index(ex):\n",
    "    return [(len(x) - x[::-1].index(1)) for x in ex.token_type_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3862bc1-1f25-481f-b8ba-3331342b4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_row(row, hf_dataset=True):\n",
    "    tokenized_row = tokenizer(row[\"question\"],\n",
    "                              row[\"context\"],\n",
    "                              max_length=max_length,\n",
    "                              truncation=\"only_second\",\n",
    "                              padding=\"max_length\",\n",
    "                              stride=doc_stride,\n",
    "                              return_overflowing_tokens = True,\n",
    "                              return_offsets_mapping = True)    \n",
    "    tokenized_row[\"start_positions\"] = []\n",
    "    tokenized_row[\"end_positions\"] = []\n",
    "    context_starts = context_start_token_index(tokenized_row)\n",
    "    context_ends = context_end_token_index(tokenized_row)\n",
    "    index = tokenized_row[\"overflow_to_sample_mapping\"]\n",
    "\n",
    "    \n",
    "    for i, o in enumerate(tokenized_row[\"offset_mapping\"]):\n",
    "        \n",
    "        if hf_dataset:\n",
    "            start_ch = row[\"answers\"][index[i]][\"answer_start\"][0]\n",
    "            end_ch = start_ch + len(row[\"answers\"][index[i]][\"text\"][0])\n",
    "        else:\n",
    "            start_ch = row[\"answers\"][\"answer_start\"][0]\n",
    "            end_ch = start_ch + len(row[\"answers\"][\"text\"][0])\n",
    "\n",
    "        \n",
    "        cls_ind = tokenized_row[\"input_ids\"][i].index(tokenizer.cls_token_id)\n",
    "        start = context_starts[i]\n",
    "        end = context_ends[i] - 2\n",
    "        if start_ch < o[start][0] or end_ch > o[end][1]:\n",
    "            tokenized_row[\"start_positions\"].append(cls_ind)\n",
    "            tokenized_row[\"end_positions\"].append(cls_ind)\n",
    "        else:\n",
    "            while o[start][0] < start_ch:\n",
    "                start += 1\n",
    "            while o[end][1] > end_ch:\n",
    "                end -= 1\n",
    "                if start > end:\n",
    "                    end += 1\n",
    "                    break\n",
    "            tokenized_row[\"start_positions\"].append(start)\n",
    "            tokenized_row[\"end_positions\"].append(end)\n",
    "            \n",
    "    return tokenized_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efaa2089-0764-482f-b4b4-32e604902403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff87ad-9a1d-4048-9551-ba8acd91187d",
   "metadata": {},
   "source": [
    "#### Delete questions with answers that contain tokens not recognised by models tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b965ae5-2d51-43fc-8312-6773b9c74a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking all answers and answers in contexts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9954/9954 [01:43<00:00, 95.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 134 questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data = []\n",
    "for row in tqdm(df_train.iloc, total=df_train.shape[0], desc=\"Checking all answers and answers in contexts\"):\n",
    "    #print(row.question, row.answers[\"text\"])\n",
    "    test = get_tokenized_row(row, hf_dataset=False)\n",
    "    answers = []\n",
    "    #print(row.answers[\"text\"])\n",
    "    #print(test[\"start_positions\"])\n",
    "    #print(test[\"end_positions\"])\n",
    "    for i, z in enumerate(zip(test[\"start_positions\"],test[\"end_positions\"])):\n",
    "        x=test[\"input_ids\"][i][z[0]:z[1]+1]\n",
    "        #print(tokenizer.decode(x))\n",
    "        answers.append(tokenizer.decode(x))\n",
    "    if row.answers[\"text\"][0].replace(' ', '').lower() not in [x.replace(' ','').lower() for x in answers]:\n",
    "        count += 1\n",
    "        continue\n",
    "    data.append([row.answers, row.question, row.context, row.id, row.title])\n",
    "print(\"Deleted\",count,\"questions\")\n",
    "data_df = pd.DataFrame(data, columns=[\"answers\", \"question\", \"context\", \"id\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295ea42-f236-4357-917b-145f5798e336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e72933f-d9b1-4cdb-aae1-49f4843fbd88",
   "metadata": {},
   "source": [
    "### Load SQAD to Huggingface dataset form pandas and split it into train and validation parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34549b65-c399-42a9-840f-481a79ed1b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'question', 'context', 'id', 'title'],\n",
       "        num_rows: 8838\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'question', 'context', 'id', 'title'],\n",
       "        num_rows: 982\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(data_df)\n",
    "train_dataset = train_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49638-b169-4b71-a1cb-4f3ef0fe00de",
   "metadata": {},
   "source": [
    "### Tokenize and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10f1a649-08e8-4cce-823d-37366c142e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_tokenized_row at 0x00000256B4E59AF0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [10:25<00:00, 69.53s/ba]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:05<00:00, 65.37s/ba]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(get_tokenized_row, remove_columns=train_dataset[\"train\"].column_names, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2939a954-a26c-4482-baf8-9ae9641e736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'start_positions', 'end_positions'],\n",
       "        num_rows: 112665\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'start_positions', 'end_positions'],\n",
       "        num_rows: 12207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "885f4452-d0b4-454f-a91d-fbbfaaa108fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 112665\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 12207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove unused columns\n",
    "\n",
    "tokenized_train_dataset[\"train\"] = tokenized_train_dataset[\"train\"].remove_columns(\"offset_mapping\")\n",
    "tokenized_train_dataset[\"test\"] = tokenized_train_dataset[\"test\"].remove_columns(\"offset_mapping\")\n",
    "tokenized_train_dataset[\"train\"] = tokenized_train_dataset[\"train\"].remove_columns(\"overflow_to_sample_mapping\")\n",
    "tokenized_train_dataset[\"test\"] = tokenized_train_dataset[\"test\"].remove_columns(\"overflow_to_sample_mapping\")\n",
    "tokenized_train_dataset[\"train\"] = tokenized_train_dataset[\"train\"].remove_columns(\"token_type_ids\")\n",
    "tokenized_train_dataset[\"test\"] = tokenized_train_dataset[\"test\"].remove_columns(\"token_type_ids\")\n",
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1cdf0-1b95-498f-99fe-404647b15a6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc043909-c01c-4aaf-83d4-1029d1496dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aec77095-2e03-4588-a56d-175c517248aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UWB-AIR/Czert-B-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at UWB-AIR/Czert-B-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name, num_labels=2)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68854cb9-3a10-4a3b-a358-809cd074c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fd274cf-1b87-445a-8168-8c495d4d44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arg = TrainingArguments(\n",
    "                \"BERT_czech_finetuned_sqad\",\n",
    "                evaluation_strategy = \"epoch\",\n",
    "                learning_rate = 3e-5,\n",
    "                num_train_epochs = 3,\n",
    "                weight_decay = 0.1,\n",
    "                per_device_train_batch_size = 16,\n",
    "                per_device_eval_batch_size = 16,\n",
    "                save_total_limit=2\n",
    "                )\n",
    "\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e887ab17-7049-40f1-b366-96f46d804c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "            model,\n",
    "            training_arg,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=tokenized_train_dataset[\"train\"],\n",
    "            eval_dataset=tokenized_train_dataset[\"test\"],\n",
    "            tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c0e7a-a092-47f6-a60c-35b916fedd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404d855-b3d6-4d0c-8072-ba3e3f02b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"BERT_czech_finetuned_sqad\\\\bert-czech-finetuned-sqad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
