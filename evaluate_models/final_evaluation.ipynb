{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aea6c296-db21-415c-b788-1df846ac78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import string\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbcd6e-e98f-4b8d-aede-880f89ca54c5",
   "metadata": {},
   "source": [
    "#### Load test SQAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b3f37e4-f4fd-4b79-8bf5-98a9dba229c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>answer_sentence_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [12], 'text': ['levostranný']}</td>\n",
       "      <td>Dřevnice je levostranný přítok řeky Moravy ve ...</td>\n",
       "      <td>12242</td>\n",
       "      <td>Jaký přítok je Dřevnice?</td>\n",
       "      <td>Jaký přítok je Dřevnice?</td>\n",
       "      <td>Dřevnice je levostranný přítok řeky Moravy ve ...</td>\n",
       "      <td>[0, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [0], 'text': ['ve Foxrocku']}</td>\n",
       "      <td>Samuel Barclay Beckett [Bekit] (13. dubna 1906...</td>\n",
       "      <td>2490</td>\n",
       "      <td>Kde se narodil Samuel Beckett?</td>\n",
       "      <td>Kde se narodil Samuel Beckett?</td>\n",
       "      <td>Samuel Barclay Beckett [Bekit] (13. dubna 1906...</td>\n",
       "      <td>[0, 130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [216], 'text': ['Josef Ressel']}</td>\n",
       "      <td>Buzola (také busola) je jednoduchý přístroj pr...</td>\n",
       "      <td>5571</td>\n",
       "      <td>Který český vynálezce sestrojil první buzolu?</td>\n",
       "      <td>Který český vynálezce sestrojil první buzolu?</td>\n",
       "      <td>První buzolu sestrojil český vynálezce Josef R...</td>\n",
       "      <td>[177, 229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [2084], 'text': ['1869']}</td>\n",
       "      <td>Deoxyribonukleová kyselina, běžně označovaná D...</td>\n",
       "      <td>7325</td>\n",
       "      <td>Ve kterém roce byla popsána deoxyribonukleová ...</td>\n",
       "      <td>Ve kterém roce byla popsána deoxyribonukleová ...</td>\n",
       "      <td>Deoxyribonukleová kyselina byla popsána roku 1...</td>\n",
       "      <td>[2039, 2173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [168], 'text': ['strojové ins...</td>\n",
       "      <td>Centrální procesorová jednotka (zkratka CPU, a...</td>\n",
       "      <td>3770</td>\n",
       "      <td>Co vykonává procesor?</td>\n",
       "      <td>Co vykonává procesor?</td>\n",
       "      <td>Centrální procesorová jednotka (zkratka CPU, a...</td>\n",
       "      <td>[0, 263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>{'answer_start': [1137], 'text': ['na počátku ...</td>\n",
       "      <td>Gainax (japonsky ガ, Gainakkusu) je japonské an...</td>\n",
       "      <td>4817</td>\n",
       "      <td>Kdy bylo založeno studio Gainax?</td>\n",
       "      <td>Kdy bylo založeno studio Gainax?</td>\n",
       "      <td>Studio Gainax bylo založeno na počátku 80. let...</td>\n",
       "      <td>[1109, 1278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>{'answer_start': [830], 'text': ['Titan je šed...</td>\n",
       "      <td>Titan (chemická značka Ti, latinsky Titanium) ...</td>\n",
       "      <td>11707</td>\n",
       "      <td>Je titan lehký kov?</td>\n",
       "      <td>Je titan lehký kov?</td>\n",
       "      <td>Titan je šedý až stříbřitě bílý, lehký a tvrdý...</td>\n",
       "      <td>[830, 881]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>{'answer_start': [17], 'text': ['10. března 19...</td>\n",
       "      <td>Eva Herzigová (* 10. března 1973 Litvínov) je ...</td>\n",
       "      <td>5771</td>\n",
       "      <td>Kdy se narodila Eva Herzigová?</td>\n",
       "      <td>Kdy se narodila Eva Herzigová?</td>\n",
       "      <td>Eva Herzigová (* 10. března 1973 Litvínov) je ...</td>\n",
       "      <td>[0, 75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>{'answer_start': [58], 'text': ['Vladimír Štan...</td>\n",
       "      <td>Michal David (* 14. července 1960 Praha), vlas...</td>\n",
       "      <td>10738</td>\n",
       "      <td>Jak se vlastním jménem jmenuje Michal David?</td>\n",
       "      <td>Jak se vlastním jménem jmenuje Michal David?</td>\n",
       "      <td>Michal David (* 14. července 1960 Praha), vlas...</td>\n",
       "      <td>[0, 129]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>{'answer_start': [180], 'text': ['královna Sem...</td>\n",
       "      <td>Visuté zahrady Semiramidiny (také označované j...</td>\n",
       "      <td>5051</td>\n",
       "      <td>Pro kterou královnu byli vybudovány dle legend...</td>\n",
       "      <td>Pro kterou královnu byli vybudovány dle legend...</td>\n",
       "      <td>Postavit je nechala dle legendy královna Semir...</td>\n",
       "      <td>[148, 282]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answers  \\\n",
       "0       {'answer_start': [12], 'text': ['levostranný']}   \n",
       "1        {'answer_start': [0], 'text': ['ve Foxrocku']}   \n",
       "2     {'answer_start': [216], 'text': ['Josef Ressel']}   \n",
       "3            {'answer_start': [2084], 'text': ['1869']}   \n",
       "4     {'answer_start': [168], 'text': ['strojové ins...   \n",
       "...                                                 ...   \n",
       "2484  {'answer_start': [1137], 'text': ['na počátku ...   \n",
       "2485  {'answer_start': [830], 'text': ['Titan je šed...   \n",
       "2486  {'answer_start': [17], 'text': ['10. března 19...   \n",
       "2487  {'answer_start': [58], 'text': ['Vladimír Štan...   \n",
       "2488  {'answer_start': [180], 'text': ['královna Sem...   \n",
       "\n",
       "                                                context     id  \\\n",
       "0     Dřevnice je levostranný přítok řeky Moravy ve ...  12242   \n",
       "1     Samuel Barclay Beckett [Bekit] (13. dubna 1906...   2490   \n",
       "2     Buzola (také busola) je jednoduchý přístroj pr...   5571   \n",
       "3     Deoxyribonukleová kyselina, běžně označovaná D...   7325   \n",
       "4     Centrální procesorová jednotka (zkratka CPU, a...   3770   \n",
       "...                                                 ...    ...   \n",
       "2484  Gainax (japonsky ガ, Gainakkusu) je japonské an...   4817   \n",
       "2485  Titan (chemická značka Ti, latinsky Titanium) ...  11707   \n",
       "2486  Eva Herzigová (* 10. března 1973 Litvínov) je ...   5771   \n",
       "2487  Michal David (* 14. července 1960 Praha), vlas...  10738   \n",
       "2488  Visuté zahrady Semiramidiny (také označované j...   5051   \n",
       "\n",
       "                                                  title  \\\n",
       "0                              Jaký přítok je Dřevnice?   \n",
       "1                        Kde se narodil Samuel Beckett?   \n",
       "2         Který český vynálezce sestrojil první buzolu?   \n",
       "3     Ve kterém roce byla popsána deoxyribonukleová ...   \n",
       "4                                 Co vykonává procesor?   \n",
       "...                                                 ...   \n",
       "2484                   Kdy bylo založeno studio Gainax?   \n",
       "2485                                Je titan lehký kov?   \n",
       "2486                     Kdy se narodila Eva Herzigová?   \n",
       "2487       Jak se vlastním jménem jmenuje Michal David?   \n",
       "2488  Pro kterou královnu byli vybudovány dle legend...   \n",
       "\n",
       "                                               question  \\\n",
       "0                              Jaký přítok je Dřevnice?   \n",
       "1                        Kde se narodil Samuel Beckett?   \n",
       "2         Který český vynálezce sestrojil první buzolu?   \n",
       "3     Ve kterém roce byla popsána deoxyribonukleová ...   \n",
       "4                                 Co vykonává procesor?   \n",
       "...                                                 ...   \n",
       "2484                   Kdy bylo založeno studio Gainax?   \n",
       "2485                                Je titan lehký kov?   \n",
       "2486                     Kdy se narodila Eva Herzigová?   \n",
       "2487       Jak se vlastním jménem jmenuje Michal David?   \n",
       "2488  Pro kterou královnu byli vybudovány dle legend...   \n",
       "\n",
       "                                        answer_sentence answer_sentence_span  \n",
       "0     Dřevnice je levostranný přítok řeky Moravy ve ...              [0, 61]  \n",
       "1     Samuel Barclay Beckett [Bekit] (13. dubna 1906...             [0, 130]  \n",
       "2     První buzolu sestrojil český vynálezce Josef R...           [177, 229]  \n",
       "3     Deoxyribonukleová kyselina byla popsána roku 1...         [2039, 2173]  \n",
       "4     Centrální procesorová jednotka (zkratka CPU, a...             [0, 263]  \n",
       "...                                                 ...                  ...  \n",
       "2484  Studio Gainax bylo založeno na počátku 80. let...         [1109, 1278]  \n",
       "2485  Titan je šedý až stříbřitě bílý, lehký a tvrdý...           [830, 881]  \n",
       "2486  Eva Herzigová (* 10. března 1973 Litvínov) je ...              [0, 75]  \n",
       "2487  Michal David (* 14. července 1960 Praha), vlas...             [0, 129]  \n",
       "2488  Postavit je nechala dle legendy královna Semir...           [148, 282]  \n",
       "\n",
       "[2489 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(\"czech_test_answer_sentence.json\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a5959-4c6b-4171-a2e2-c1af3c602bac",
   "metadata": {},
   "source": [
    "### Functions each evaluating different taks and different metric (Answer Extraction, Answer Selections and exact_match@k and partial_match@k for each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5230501-82b9-4aad-acc1-91e9b74a68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_match(answer, preds):\n",
    "    #function returns tuple of booleans for\n",
    "    # exact match, em in top 5, top 10, top 20\n",
    "    answer = answer.strip().strip(string.punctuation)\n",
    "    for i, prediction in enumerate(preds):\n",
    "        #remove spaces and punctuations\n",
    "        p = prediction[\"text\"].strip().strip(string.punctuation)\n",
    "        if p == answer:\n",
    "            if  i + 1 == 1:\n",
    "                return (True, True, True, True)\n",
    "            elif i + 1 <= 5:\n",
    "                return (False, True, True, True)\n",
    "            elif i + 1 <= 10:\n",
    "                return (False, False, True, True)\n",
    "            elif i + 1 <= 20:\n",
    "                return (False, False, False, True)\n",
    "    return (False, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f78a7393-5345-4a34-a44d-5f28f07c7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage_match(answer, answer_start, preds):\n",
    "    answer_end = answer_start + len(answer)\n",
    "    #function returns tuple of booleans for\n",
    "    # coverage match, cm in top 5, top 10, top 20\n",
    "    cm = False\n",
    "    cm5 = False\n",
    "    cm10 = False\n",
    "    cm20 = False\n",
    "    for i, prediction in enumerate(preds):\n",
    "        pred_span = tuple([prediction[\"text_start\"], prediction[\"text_start\"]+len(prediction[\"text\"])])\n",
    "        if (pred_span[0] < answer_start and answer_start < pred_span[1] <= answer_end) \\\n",
    "        or (pred_span[0] >= answer_start and pred_span[1] <= answer_end)\\\n",
    "        or (answer_start <= pred_span[0] < answer_end and pred_span[1] > answer_end)\\\n",
    "        or (pred_span[0] > answer_start and pred_span[1] < answer_end):\n",
    "            if i + 1 == 1:\n",
    "                cm, cm5, cm10, cm20 = True, True, True, True\n",
    "            elif i + 1  <= 5 and not cm:\n",
    "                cm, cm5, cm10, cm20 = False, True, True, True\n",
    "            elif i + 1  <= 10 and not cm and not cm5:\n",
    "                cm, cm5, cm10, cm20 = False, False, True, True\n",
    "            elif i + 1  <= 20 and not cm and not cm5 and not cm10:\n",
    "                cm, cm5, cm10, cm20 = False, False, False, True\n",
    "        if any([cm, cm5, cm10, cm20]):\n",
    "            return (cm, cm5, cm10, cm20)\n",
    "    return (False, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5315d055-cc03-476f-b4cc-87d192b3df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage_match_T5(answer, preds):\n",
    "    #function returns tuple of booleans for\n",
    "    # coverage match, cm in top 5, top 10, top 20\n",
    "    cm = False\n",
    "    cm5 = False\n",
    "    cm10 = False\n",
    "    cm20 = False\n",
    "    for i, prediction in enumerate(preds):\n",
    "        tokens = prediction[\"text\"].split()\n",
    "        for t in tokens:\n",
    "            if t in answer:\n",
    "                if i + 1 == 1:\n",
    "                    cm, cm5, cm10, cm20 = True, True, True, True\n",
    "                elif i + 1  <= 5 and not cm:\n",
    "                    cm, cm5, cm10, cm20 = False, True, True, True\n",
    "                elif i + 1  <= 10 and not cm and not cm5:\n",
    "                    cm, cm5, cm10, cm20 = False, False, True, True\n",
    "                elif i + 1  <= 20 and not cm and not cm5 and not cm10:\n",
    "                    cm, cm5, cm10, cm20 = False, False, False, True\n",
    "        if any([cm, cm5, cm10, cm20]):\n",
    "            return (cm, cm5, cm10, cm20)\n",
    "    return (False, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "80cbfd20-091e-4537-a54e-ef5914c5970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_selection_em(answer_sentence_span, preds):\n",
    "    #function checks if the model selected the right sentence on exact_match\n",
    "    for i, prediction in enumerate(preds):\n",
    "        span = tuple([prediction[\"text_start\"], prediction[\"text_start\"]+len(prediction[\"text\"])])\n",
    "        if span[0] >= answer_sentence_span[0] and span[1] <= answer_sentence_span[1]:\n",
    "            if i + 1 == 1:\n",
    "                return True, True, True, True\n",
    "            elif i + 1 <= 5:\n",
    "                return False, True, True, True\n",
    "            elif i + 1 <= 10:\n",
    "                return False, False, True, True\n",
    "            elif i + 1 <= 20:\n",
    "                return False, False, False, True\n",
    "    return False, False, False, False\n",
    "\n",
    "def get_answer_selection_cm(answer_sentence_span, preds):\n",
    "    #function checks if the model selected the right sentence on coverage match\n",
    "    for i, prediction in enumerate(preds):\n",
    "        span = tuple([prediction[\"text_start\"], prediction[\"text_start\"]+len(prediction[\"text\"])])\n",
    "        if (span[0] < answer_sentence_span[0] and answer_sentence_span[0] < span[1] <= answer_sentence_span[1])\\\n",
    "        or (span[0] >= answer_sentence_span[0] and span[1] <= answer_sentence_span[1])\\\n",
    "        or (answer_sentence_span[0] <= span[0] < answer_sentence_span[1] and span[1] > answer_sentence_span[1])\\\n",
    "        or (span[0] > answer_sentence_span[0] and span[1] < answer_sentence_span[1]):\n",
    "            if i + 1 == 1:\n",
    "                return True, True, True, True\n",
    "            elif i + 1 <= 5:\n",
    "                return False, True, True, True\n",
    "            elif i + 1 <= 10:\n",
    "                return False, False, True, True\n",
    "            elif i + 1 <= 20:\n",
    "                return False, False, False, True\n",
    "    return False, False, False, False\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "45e5ca16-ab52-4977-a41b-65f34d0afb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, predictions_data, model_name):\n",
    "    #evaluate model on answer selection and extraction\n",
    "    exact_match = 0\n",
    "    exact_match5 = 0\n",
    "    exact_match10 = 0\n",
    "    exact_match20 = 0\n",
    "\n",
    "    coverage_match = 0\n",
    "    coverage_match5 = 0\n",
    "    coverage_match10 = 0\n",
    "    coverage_match20 = 0\n",
    "\n",
    "    answer_sentence = 0\n",
    "    answer_sentence5 = 0\n",
    "    answer_sentence10 = 0\n",
    "    answer_sentence20 = 0\n",
    "\n",
    "    answer_sentence_coverage = 0\n",
    "    answer_sentence_coverage5 = 0\n",
    "    answer_sentence_coverage10 = 0\n",
    "    answer_sentence_coverage20 = 0\n",
    "    for row in dataset.iloc:\n",
    "        #print(row.answers)\n",
    "        answer = row.answers[\"text\"][0]\n",
    "        answer_start = row.answers[\"answer_start\"][0]\n",
    "        answer_sentence_span = row.answer_sentence_span\n",
    "        #print(row.id)\n",
    "        predictions = predictions_data[row.id]\n",
    "\n",
    "        em = get_exact_match(answer, predictions)\n",
    "        exact_match += em[0]\n",
    "        exact_match5 += em[1]\n",
    "        exact_match10 += em[2]\n",
    "        exact_match20 += em[3]\n",
    "\n",
    "        cm = get_coverage_match(answer, answer_start, predictions)\n",
    "        coverage_match += cm[0]\n",
    "        coverage_match5 += cm[1]\n",
    "        coverage_match10 += cm[2]\n",
    "        coverage_match20 += cm[3]\n",
    "\n",
    "        ans_selection = get_answer_selection_em(answer_sentence_span, predictions)\n",
    "        answer_sentence += ans_selection[0]\n",
    "        answer_sentence5 += ans_selection[1]\n",
    "        answer_sentence10 += ans_selection[2]\n",
    "        answer_sentence20 += ans_selection[3]\n",
    "\n",
    "        ans_selection_coverage = get_answer_selection_cm(answer_sentence_span, predictions)\n",
    "        answer_sentence_coverage += ans_selection_coverage[0]\n",
    "        answer_sentence_coverage5 += ans_selection_coverage[1]\n",
    "        answer_sentence_coverage10 += ans_selection_coverage[2]\n",
    "        answer_sentence_coverage20 += ans_selection_coverage[3]\n",
    "        \n",
    "    results = {\"model_name\": model_name}\n",
    "    \n",
    "    results[\"answer_exact_match\"] = exact_match/dataset.shape[0]\n",
    "    results[\"answer_exact_match_5\"] = exact_match5/dataset.shape[0]\n",
    "    results[\"answer_exact_match_10\"] = exact_match10/dataset.shape[0]\n",
    "    results[\"answer_exact_match_20\"] = exact_match20/dataset.shape[0]\n",
    "    \n",
    "    print(\"Answer extraction results for: \" + model_name)\n",
    "    print(\"EXACT MATCH:        {:0.4f}\".format(exact_match/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 5:  {:0.4f}\".format(exact_match5/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 10: {:0.4f}\".format(exact_match10/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 20: {:0.4f}\".format(exact_match20/dataset.shape[0]))\n",
    "\n",
    "    results[\"answer_coverage_match\"] = coverage_match/dataset.shape[0]\n",
    "    results[\"answer_coverage_match_5\"] = coverage_match5/dataset.shape[0]\n",
    "    results[\"answer_coverage_match_10\"] = coverage_match10/dataset.shape[0]\n",
    "    results[\"answer_coverage_match_20\"] = coverage_match20/dataset.shape[0]\n",
    "    \n",
    "    print(\"COVERAGE MATCH:        {:0.4f}\".format(coverage_match/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 5:  {:0.4f}\".format(coverage_match5/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 10: {:0.4f}\".format(coverage_match10/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 20: {:0.4f}\".format(coverage_match20/dataset.shape[0]))\n",
    "\n",
    "    print(\"\\nAnswer selection results for: \" + model_name)\n",
    "    \n",
    "    results[\"answer_sentence_exact_match\"] = answer_sentence/dataset.shape[0]\n",
    "    results[\"answer_sentence_exact_match_5\"] = answer_sentence5/dataset.shape[0]\n",
    "    results[\"answer_sentence_exact_match_10\"] = answer_sentence10/dataset.shape[0]\n",
    "    results[\"answer_sentence_exact_match_20\"] = answer_sentence20/dataset.shape[0]\n",
    "    \n",
    "    print(\"EXACT MATCH:        {:0.4f}\".format(answer_sentence/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 5:  {:0.4f}\".format(answer_sentence5/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 10: {:0.4f}\".format(answer_sentence10/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 20: {:0.4f}\".format(answer_sentence20/dataset.shape[0]))\n",
    "\n",
    "    results[\"answer_sentence_coverage_match\"] = answer_sentence_coverage/dataset.shape[0]\n",
    "    results[\"answer_sentence_coverage_match_5\"] = answer_sentence_coverage5/dataset.shape[0]\n",
    "    results[\"answer_sentence_coverage_match_10\"] = answer_sentence_coverage10/dataset.shape[0]\n",
    "    results[\"answer_sentence_coverage_match_20\"] = answer_sentence_coverage20/dataset.shape[0]\n",
    "    \n",
    "    print(\"COVERAGE MATCH:        {:0.4f}\".format(answer_sentence_coverage/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 5:  {:0.4f}\".format(answer_sentence_coverage5/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 10: {:0.4f}\".format(answer_sentence_coverage10/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 20: {:0.4f}\".format(answer_sentence_coverage20/dataset.shape[0]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "72f52efb-ac68-4397-925b-656de8ccd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(test_dataset):\n",
    "    #run evaluation of bert-like models\n",
    "    models = [\"albert_czech\", \"bert_czech\", \"bert_multilingual\", \"bert_slavic\", \"electra_czech\", \"roberta_czech\", \"roberta_multilingual\"]\n",
    "    df = []\n",
    "    for m in models:\n",
    "        with open(\"model_predictions\\\\{}_predictions.json\".format(m), 'rb') as fp:\n",
    "            predictions_data = pickle.load(fp)\n",
    "            print(100*'-'+\"\\n\"+fp.name+\"\\n\"+100*'-')   \n",
    "            #print(predictions_data[5571])\n",
    "        df += [evaluate_model(test_dataset, predictions_data, m)]\n",
    "    data_frame = pd.DataFrame(df)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3330b01e-15cf-4ec1-810c-7924118efa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2489"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"model_predictions\\\\T5_multilingual_predictions.json\", 'rb') as fp:\n",
    "    predictions_data = pickle.load(fp)\n",
    "len(predictions_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9e15da96-b86a-4454-b699-c75228ff9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the numver of different characters in 2 strings\n",
    "def get_different_chars(a, b):\n",
    "    for a_ch in a:\n",
    "        #print(a_ch)\n",
    "        b = b.replace(a_ch,\"\")\n",
    "    return len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "35e25071-7b13-4352-a292-0b1c34bec593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_different_chars(\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "afa54355-8321-4fdd-9a75-8ad1294ddb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_only_additional_punctuation(answer, prediction):\n",
    "    #checks if prediction is relevant after stripping punctuation\n",
    "    if prediction.strip().strip(string.punctuation) == answer:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e702b33-ad87-4790-a8da-2fc8643cfc14",
   "metadata": {},
   "source": [
    "#### Get the average number of different characters in predictions and answer and umber of answers which would be exact match with punctuation removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7856d15a-7bd9-4975-b357-4060c1fa68bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions that would be correct with punctuation stripping: 1\n",
      "Final character difference count: 5.434692647649656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_sum_of_means = 0\n",
    "number_of_q_with_punctuation = 0\n",
    "for row in dataset.iloc:\n",
    "    different = 0\n",
    "    only_punct_different = False\n",
    "    pred_answers = [x[\"text\"] for x in predictions_data[row.id]]\n",
    "    answer = row.answers[\"text\"][0]\n",
    "    flag = False\n",
    "    for p in pred_answers:\n",
    "        if p == answer:\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        for p in pred_answers:\n",
    "            different+=get_different_chars(p, answer)\n",
    "            if check_if_only_additional_punctuation(answer, p):\n",
    "                only_punct_different = True\n",
    "        #print(answer)\n",
    "        #print(pred_answers)\n",
    "        #print(different/20)\n",
    "        total_sum_of_means += different/20\n",
    "    if only_punct_different:\n",
    "        number_of_q_with_punctuation += 1\n",
    "print(\"Number of predictions that would be correct with punctuation stripping:\",number_of_q_with_punctuation)\n",
    "print(\"Final character difference count:\", total_sum_of_means/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "765f6e5c-c4d4-432b-9c02-2d3fe046f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8312\n",
      "Na kterém pólu Země je Antarktida?\n",
      "jižní\n",
      "Jižním, Jižním, jižního, Jižním pólu, jižním, Jižního, na Jižním, Ježním, jižního pólu, Jižním polou, Jižní, Na Jižním, Jinžním, Jižním polu, Jižním,, Jižní, Jižním?, jižním, Jižním, Jinžního, "
     ]
    }
   ],
   "source": [
    "# Example of mT5 generating correct answers but with different spelling and upper and lower cases\n",
    "for row in dataset.iloc:\n",
    "    pred_answers = [x[\"text\"] for x in predictions_data[row.id]]\n",
    "    answer = row.answers[\"text\"][0]\n",
    "    flag = False\n",
    "    for p in pred_answers:\n",
    "        if p == answer:\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        if row.id==8312:\n",
    "            print(row.id)\n",
    "            print(row.question)\n",
    "            print(answer)\n",
    "            for x in pred_answers:\n",
    "                print(x,end=\", \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f2090e22-6651-4d18-adc5-7ad1c9d0dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_T5(dataset, predictions_data):\n",
    "    #evaluate T5 model on answer selection and extracton\n",
    "    exact_match = 0\n",
    "    exact_match5 = 0\n",
    "    exact_match10 = 0\n",
    "    exact_match20 = 0\n",
    "\n",
    "    coverage_match = 0\n",
    "    coverage_match5 = 0\n",
    "    coverage_match10 = 0\n",
    "    coverage_match20 = 0\n",
    "    \n",
    "    answer_sentence = 0\n",
    "    answer_sentence5 = 0\n",
    "    answer_sentence10 = 0\n",
    "    answer_sentence20 = 0\n",
    "    \n",
    "    answer_sentence_coverage = 0\n",
    "    answer_sentence_coverage5 = 0\n",
    "    answer_sentence_coverage10 = 0\n",
    "    answer_sentence_coverage20 = 0\n",
    "\n",
    "    for row in dataset.iloc:\n",
    "        #print(row.answers)\n",
    "        answer = row.answers[\"text\"][0]\n",
    "        predictions = predictions_data[row.id]\n",
    "        answer_sent = row[\"answer_sentence\"]\n",
    "\n",
    "        em = get_exact_match(answer, predictions)\n",
    "        exact_match += em[0]\n",
    "        exact_match5 += em[1]\n",
    "        exact_match10 += em[2]\n",
    "        exact_match20 += em[3]\n",
    "\n",
    "        cm = get_coverage_match_T5(answer, predictions)\n",
    "        coverage_match += cm[0]\n",
    "        coverage_match5 += cm[1]\n",
    "        coverage_match10 += cm[2]\n",
    "        coverage_match20 += cm[3]\n",
    "\n",
    "       \n",
    "    print(\"Answer extraction results for T5_multilingual \")\n",
    "    \n",
    "    print(\"EXACT MATCH:        {:0.4f}\".format(exact_match/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 5:  {:0.4f}\".format(exact_match5/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 10: {:0.4f}\".format(exact_match10/dataset.shape[0]))\n",
    "    print(\"EXACT MATCH TOP 20: {:0.4f}\".format(exact_match20/dataset.shape[0]))\n",
    "    \n",
    "    print(\"COVERAGE MATCH:        {:0.4f}\".format(coverage_match/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 5:  {:0.4f}\".format(coverage_match5/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 10: {:0.4f}\".format(coverage_match10/dataset.shape[0]))\n",
    "    print(\"COVERAGE MATCH TOP 20: {:0.4f}\".format(coverage_match20/dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358b12a-3cfa-49d5-861c-1a43c67b07d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_model_T5(dataset, predictions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3ddc3-90d5-422e-8530-1c5439b542e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_evaluation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5cf85eb6-13e2-4e6e-b429-4854b7649a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_exact_match</th>\n",
       "      <th>answer_exact_match_5</th>\n",
       "      <th>answer_exact_match_10</th>\n",
       "      <th>answer_exact_match_20</th>\n",
       "      <th>answer_coverage_match</th>\n",
       "      <th>answer_coverage_match_5</th>\n",
       "      <th>answer_coverage_match_10</th>\n",
       "      <th>answer_coverage_match_20</th>\n",
       "      <th>answer_sentence_exact_match</th>\n",
       "      <th>answer_sentence_exact_match_5</th>\n",
       "      <th>answer_sentence_exact_match_10</th>\n",
       "      <th>answer_sentence_exact_match_20</th>\n",
       "      <th>answer_sentence_coverage_match</th>\n",
       "      <th>answer_sentence_coverage_match_5</th>\n",
       "      <th>answer_sentence_coverage_match_10</th>\n",
       "      <th>answer_sentence_coverage_match_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.679447</td>\n",
       "      <td>0.816909</td>\n",
       "      <td>0.854044</td>\n",
       "      <td>0.882512</td>\n",
       "      <td>0.820238</td>\n",
       "      <td>0.911955</td>\n",
       "      <td>0.937324</td>\n",
       "      <td>0.957929</td>\n",
       "      <td>0.840154</td>\n",
       "      <td>0.901854</td>\n",
       "      <td>0.922918</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.868220</td>\n",
       "      <td>0.937037</td>\n",
       "      <td>0.957700</td>\n",
       "      <td>0.972680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074483</td>\n",
       "      <td>0.071815</td>\n",
       "      <td>0.068275</td>\n",
       "      <td>0.061923</td>\n",
       "      <td>0.067374</td>\n",
       "      <td>0.052642</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>0.051935</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.062505</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.019253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.564484</td>\n",
       "      <td>0.705504</td>\n",
       "      <td>0.745681</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.718361</td>\n",
       "      <td>0.829249</td>\n",
       "      <td>0.880273</td>\n",
       "      <td>0.913218</td>\n",
       "      <td>0.719566</td>\n",
       "      <td>0.802732</td>\n",
       "      <td>0.838489</td>\n",
       "      <td>0.875854</td>\n",
       "      <td>0.769787</td>\n",
       "      <td>0.867818</td>\n",
       "      <td>0.912816</td>\n",
       "      <td>0.944154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.634793</td>\n",
       "      <td>0.769385</td>\n",
       "      <td>0.809361</td>\n",
       "      <td>0.839293</td>\n",
       "      <td>0.780032</td>\n",
       "      <td>0.878666</td>\n",
       "      <td>0.909200</td>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.778827</td>\n",
       "      <td>0.857172</td>\n",
       "      <td>0.887907</td>\n",
       "      <td>0.911008</td>\n",
       "      <td>0.830655</td>\n",
       "      <td>0.911410</td>\n",
       "      <td>0.938530</td>\n",
       "      <td>0.959020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.882282</td>\n",
       "      <td>0.912816</td>\n",
       "      <td>0.838489</td>\n",
       "      <td>0.937324</td>\n",
       "      <td>0.955002</td>\n",
       "      <td>0.969064</td>\n",
       "      <td>0.875050</td>\n",
       "      <td>0.936119</td>\n",
       "      <td>0.951386</td>\n",
       "      <td>0.964644</td>\n",
       "      <td>0.887907</td>\n",
       "      <td>0.957011</td>\n",
       "      <td>0.971474</td>\n",
       "      <td>0.982322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.732624</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.908196</td>\n",
       "      <td>0.931900</td>\n",
       "      <td>0.871233</td>\n",
       "      <td>0.949980</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.981117</td>\n",
       "      <td>0.904178</td>\n",
       "      <td>0.949578</td>\n",
       "      <td>0.963037</td>\n",
       "      <td>0.972077</td>\n",
       "      <td>0.915428</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.979510</td>\n",
       "      <td>0.986943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.754520</td>\n",
       "      <td>0.880675</td>\n",
       "      <td>0.915227</td>\n",
       "      <td>0.936119</td>\n",
       "      <td>0.882282</td>\n",
       "      <td>0.959823</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.920450</td>\n",
       "      <td>0.960627</td>\n",
       "      <td>0.968662</td>\n",
       "      <td>0.977501</td>\n",
       "      <td>0.927682</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.983528</td>\n",
       "      <td>0.990358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       answer_exact_match  answer_exact_match_5  answer_exact_match_10  \\\n",
       "count            7.000000              7.000000               7.000000   \n",
       "mean             0.679447              0.816909               0.854044   \n",
       "std              0.074483              0.071815               0.068275   \n",
       "min              0.564484              0.705504               0.745681   \n",
       "25%              0.634793              0.769385               0.809361   \n",
       "50%              0.702290              0.849337               0.882282   \n",
       "75%              0.732624              0.872037               0.908196   \n",
       "max              0.754520              0.880675               0.915227   \n",
       "\n",
       "       answer_exact_match_20  answer_coverage_match  answer_coverage_match_5  \\\n",
       "count               7.000000               7.000000                 7.000000   \n",
       "mean                0.882512               0.820238                 0.911955   \n",
       "std                 0.061923               0.067374                 0.052642   \n",
       "min                 0.786260               0.718361                 0.829249   \n",
       "25%                 0.839293               0.780032                 0.878666   \n",
       "50%                 0.912816               0.838489                 0.937324   \n",
       "75%                 0.931900               0.871233                 0.949980   \n",
       "max                 0.936119               0.882282                 0.959823   \n",
       "\n",
       "       answer_coverage_match_10  answer_coverage_match_20  \\\n",
       "count                  7.000000                  7.000000   \n",
       "mean                   0.937324                  0.957929   \n",
       "std                    0.039264                  0.029440   \n",
       "min                    0.880273                  0.913218   \n",
       "25%                    0.909200                  0.938128   \n",
       "50%                    0.955002                  0.969064   \n",
       "75%                    0.967256                  0.981117   \n",
       "max                    0.973082                  0.984733   \n",
       "\n",
       "       answer_sentence_exact_match  answer_sentence_exact_match_5  \\\n",
       "count                     7.000000                       7.000000   \n",
       "mean                      0.840154                       0.901854   \n",
       "std                       0.080990                       0.062563   \n",
       "min                       0.719566                       0.802732   \n",
       "25%                       0.778827                       0.857172   \n",
       "50%                       0.875050                       0.936119   \n",
       "75%                       0.904178                       0.949578   \n",
       "max                       0.920450                       0.960627   \n",
       "\n",
       "       answer_sentence_exact_match_10  answer_sentence_exact_match_20  \\\n",
       "count                        7.000000                        7.000000   \n",
       "mean                         0.922918                        0.940596   \n",
       "std                          0.051935                        0.041193   \n",
       "min                          0.838489                        0.875854   \n",
       "25%                          0.887907                        0.911008   \n",
       "50%                          0.951386                        0.964644   \n",
       "75%                          0.963037                        0.972077   \n",
       "max                          0.968662                        0.977501   \n",
       "\n",
       "       answer_sentence_coverage_match  answer_sentence_coverage_match_5  \\\n",
       "count                        7.000000                          7.000000   \n",
       "mean                         0.868220                          0.937037   \n",
       "std                          0.062505                          0.042081   \n",
       "min                          0.769787                          0.867818   \n",
       "25%                          0.830655                          0.911410   \n",
       "50%                          0.887907                          0.957011   \n",
       "75%                          0.915428                          0.967256   \n",
       "max                          0.927682                          0.977099   \n",
       "\n",
       "       answer_sentence_coverage_match_10  answer_sentence_coverage_match_20  \n",
       "count                           7.000000                           7.000000  \n",
       "mean                            0.957700                           0.972680  \n",
       "std                             0.028761                           0.019253  \n",
       "min                             0.912816                           0.944154  \n",
       "25%                             0.938530                           0.959020  \n",
       "50%                             0.971474                           0.982322  \n",
       "75%                             0.979510                           0.986943  \n",
       "max                             0.983528                           0.990358  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e355842-ebac-458c-a56f-a41350c51e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"evaluated_models.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028b3d3-eb1f-4dfe-a103-27dce1b2d273",
   "metadata": {},
   "source": [
    "# Mean Reciprocal Rank and Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2ea1c2a3-b32f-4677-a7f5-091e0b9e5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrr_rank(answer, predictions, answer_sentence):\n",
    "    #return mrr for given question\n",
    "    for i, p in enumerate(predictions):\n",
    "        if answer.strip().strip(string.punctuation) in p[\"text\"] or p[\"text\"].strip().strip(string.punctuation) in answer_sentence:\n",
    "            return 1/(i+1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f4f0b673-d7d3-44f1-a8d3-ded8fc760c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(binary_vector):\n",
    "    #return average precision for given binary vector of predictions\n",
    "    m = 0\n",
    "    precs = []\n",
    "    ap = 0\n",
    "    for i, val in enumerate(binary_vector):\n",
    "        if val == 1:\n",
    "            m += 1\n",
    "            precs.append(sum(binary_vector[:i+1])/(i+1))\n",
    "    ap = (1/m)*np.sum(precs) if m else 0\n",
    "    return ap\n",
    "\n",
    "def get_average_precision(answer, predictions, answer_sentence):\n",
    "    #return average precision for given question\n",
    "    bin_vector = [int(answer.strip() in prediction[\"text\"] or prediction[\"text\"].strip() in answer_sentence) for prediction in predictions]\n",
    "    return average_precision(bin_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7374db4d-6a47-4a57-8f34-920eb1218ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_and_map(dataset, predictions_data):\n",
    "    #calculate MRR and MAP for model predictions\n",
    "    ap = 0\n",
    "    rr = 0\n",
    "    emm = 0\n",
    "    for row in dataset.iloc:\n",
    "        answer = row.answers[\"text\"][0]\n",
    "        answer_sentence = row.answer_sentence\n",
    "        predictions = predictions_data[row.id]\n",
    "        ap += get_average_precision(answer, predictions, answer_sentence)\n",
    "        rr += get_mrr_rank(answer, predictions, answer_sentence)\n",
    "    mrr = rr/dataset.shape[0]\n",
    "    mAP = ap/dataset.shape[0]\n",
    "    print(\"mAP: \", mAP)\n",
    "    print(\"mRR: \", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "14a1af30-8c2a-41a3-8f0f-3eef05e5ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_map_mrr(test_dataset):\n",
    "    #evaluate MAP and MRR\n",
    "    models = [\"albert_czech\", \"bert_czech\", \"bert_multilingual\", \"bert_slavic\", \"electra_czech\", \"roberta_czech\"]\n",
    "    df = []\n",
    "    for m in models:\n",
    "        with open(\"model_predictions\\\\{}_predictions.json\".format(m), 'rb') as fp:\n",
    "            predictions_data = pickle.load(fp)\n",
    "            print(50*'-'+\"\\n\"+fp.name+\"\\n\"+50*'-')            \n",
    "        print(m)\n",
    "        evaluate_mrr_and_map(dataset, predictions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92779fc0-73fc-4f9f-990d-f27c3e665195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_evaluation_map_mrr(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
